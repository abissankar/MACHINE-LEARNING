{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyNr1IPsvOhobKPtosdikE/n"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"FKW6ne6oDTk8"},"outputs":[],"source":["import tensorflow as tf\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","source":["import tensorflow\n","tensorflow.__version__"],"metadata":{"id":"SvS9SJ2RD21l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["DEEP LEARNING\n","\n","1.define the model\n","2.compile the model\n","3.fit the model\n","4.evaluate the model\n","5.prediction the model"],"metadata":{"id":"NCjisj0CEHn-"}},{"cell_type":"code","source":["test_data=pd.read_csv(\"https://raw.githubusercontent.com/ezioauditore-tech/AI/main/datasets/Titanic/test.csv\")\n","train_data=pd.read_csv(\"https://raw.githubusercontent.com/ezioauditore-tech/AI/main/datasets/Titanic/train.csv\")"],"metadata":{"id":"0Rd09XotE51I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data"],"metadata":{"id":"ne2EIauMIYvK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_data"],"metadata":{"id":"_CYavzbdKz1k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## delete columns that are not used as features for training and prediction\n","columns_to_drop=[\"Name\",\"Age\",\"SibSp\",\"Ticket\",\"Cabin\",\"Parch\",\"Embarked\"]\n","train_data.drop(labels=columns_to_drop,axis=1,inplace=True)\n"],"metadata":{"id":"evNWrsmUJxvN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["columns_to_drop=[\"Name\",\"Age\",\"SibSp\",\"Ticket\",\"Cabin\",\"Parch\",\"Embarked\"]\n","test_data.drop(labels=columns_to_drop,axis=1,inplace=True)"],"metadata":{"id":"Swy4QpWgLx9-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler, LabelEncoder\n","label_encoder = LabelEncoder()\n","categorical_cols = ['Sex']  # Replace with your categorical columns\n","\n","for col in categorical_cols:\n","    train_data[col] = label_encoder.fit_transform(train_data[col])\n","    test_data[col] = label_encoder.fit_transform(test_data[col])\n","\n"],"metadata":{"id":"dAXg5RehLyAG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(test_data)"],"metadata":{"id":"aoinEcZIfRHd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data.isnull().sum()"],"metadata":{"id":"opWtyxmQMH_3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_data.isnull().sum()"],"metadata":{"id":"OfB2PBnyMIC4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data"],"metadata":{"id":"Oi7PgZn9MIFL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_data"],"metadata":{"id":"H8497elLMIIn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = train_data.drop('Survived', axis=1)\n","y = train_data['Survived']"],"metadata":{"id":"Dr7s6774Igct"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","# Split into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"],"metadata":{"id":"ow_DRjAjI14V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","num_splits = 5  # You can change the number of splits as needed\n","kf = KFold(n_splits=num_splits)"],"metadata":{"id":"DGZ7tiKCNZ8k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Iterate through the splits\n","for fold, (train_index, test_index) in enumerate(kf.split(X)):\n","    print(f\"Fold: {fold + 1}\")\n","    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n","    y_train, y_test = y.iloc[train_index], y.iloc[test_index]"],"metadata":{"id":"6mo-iAxuNZ_9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Standardize features\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n"],"metadata":{"id":"52SAx68DI18I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","# Neural Network Architecture\n","model = Sequential([\n","    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n","    Dropout(0.3),  # Adding dropout for regularization\n","    Dense(64, activation='relu'),\n","    Dense(1, activation='sigmoid')\n","])"],"metadata":{"id":"L83eUQ_mI1_h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"],"metadata":{"id":"4qiDgW0SetQv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the model\n","history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))"],"metadata":{"id":"xrmig0z1etS5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate the model\n","eval_results = model.evaluate(X_test, y_test)\n","print(f\"Test Accuracy: {eval_results[1]*100:.2f}%\")"],"metadata":{"id":"3VFUq5J9etWQ"},"execution_count":null,"outputs":[]}]}